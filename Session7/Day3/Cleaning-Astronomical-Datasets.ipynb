{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Astronomical Datasets\n",
    "\n",
    "I have posed two problems for you to work on in this hands-on exercise.  \n",
    "\n",
    "- Concept drift: Do the training and test set distributions differ?\n",
    "- Find mislabeled examples in the labeled ZTF data provided\n",
    "\n",
    "More information for each is provided below.  You may want or need to cut and paste code from your other notebooks.  But first...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0a. Imports\n",
    "\n",
    "These are all the imports that will be used in this notebook.  All should be available in the DSFP conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "# You can add anything you need as you work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0b. Data Location\n",
    "\n",
    "We will use the same data from the Day 2 clustering exercise (see [that notebook](https://github.com/LSSTC-DSFP/LSSTC-DSFP-Sessions/blob/master/Session7/Day2/Clustering-Astronomical-Sources.ipynb) to download the data).\n",
    "\n",
    "Please specify paths for the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_META = '../Day2/dsfp_ztf_meta.npy'\n",
    "F_FEATS = '../Day2/dsfp_ztf_feats.npy'\n",
    "D_STAMPS = '../Day2/dsfp_ztf_png_stamps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0c. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 36 columns left.\n",
      "They are: ['diffmaglim', 'magpsf', 'sigmapsf', 'chipsf', 'magap', 'sigmagap', 'distnr', 'magnr', 'sigmagnr', 'chinr', 'sharpnr', 'sky', 'magdiff', 'fwhm', 'classtar', 'mindtoedge', 'magfromlim', 'seeratio', 'aimage', 'bimage', 'aimagerat', 'bimagerat', 'elong', 'nneg', 'nbad', 'ssdistnr', 'ssmagnr', 'sumrat', 'magapbig', 'sigmagapbig', 'ndethist', 'ncovhist', 'jdstarthist', 'jdendhist', 'scorr', 'label']\n"
     ]
    }
   ],
   "source": [
    "meta_np = np.load(F_META)\n",
    "feats_np = np.load(F_FEATS)\n",
    "\n",
    "COL_NAMES = ['diffmaglim', 'magpsf', 'sigmapsf', 'chipsf', 'magap', 'sigmagap',\n",
    "             'distnr', 'magnr', 'sigmagnr', 'chinr', 'sharpnr', 'sky',\n",
    "             'magdiff', 'fwhm', 'classtar', 'mindtoedge', 'magfromlim', 'seeratio',\n",
    "             'aimage', 'bimage', 'aimagerat', 'bimagerat', 'elong', 'nneg',\n",
    "             'nbad', 'ssdistnr', 'ssmagnr', 'sumrat', 'magapbig', 'sigmagapbig',\n",
    "             'ndethist', 'ncovhist', 'jdstarthist', 'jdendhist', 'scorr', 'label']\n",
    "\n",
    "# NOTE FROM Umaa: I've decided to eliminate the following features. Dropping them.\n",
    "#\n",
    "COL_TO_DROP = ['ndethist', 'ncovhist', 'jdstarthist', 'jdendhist', \n",
    "               'distnr', 'magnr', 'sigmagnr', 'chinr', 'sharpnr', \n",
    "               'classtar', 'ssdistnr', 'ssmagnr', 'aimagerat', 'bimagerat', \n",
    "               'magapbig', 'sigmagapbig', 'scorr']\n",
    "feats_df = pd.DataFrame(data=feats_np, index=meta_np['candid'], columns=COL_NAMES)\n",
    "print(\"There are {} columns left.\".format(len(feats_df.columns)))\n",
    "print(\"They are: {}\".format(list(feats_df.columns)))\n",
    "feats_df.drop(columns=COL_TO_DROP, inplace=True) \n",
    "#feats_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Concept Drift\n",
    "\n",
    "In the last exercise, you created a training and test set for the purposes of building a classifier.  The goal of this exercise is to note any changes in the feature distributions for these two sets.\n",
    "\n",
    "Per feature, can you:\n",
    "\n",
    "- plot test vs. train distributions for both real and bogus, and note areas that does not overlap\n",
    "- quantiatively measure this using [Kullback-Leibler divergence](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html), and print or plot the scores for all features.\n",
    "\n",
    "Which feature exhibits the most drift between train and test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['diffmaglim', 'magpsf', 'sigmapsf', 'chipsf', 'magap', 'sigmagap',\n",
      "       'sky', 'magdiff', 'fwhm', 'mindtoedge', 'magfromlim', 'seeratio',\n",
      "       'aimage', 'bimage', 'elong', 'nneg', 'nbad', 'sumrat', 'label', 'nids'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'labels = feats_plus_label[:,-1] # labels only\\nfeats_plus_label = feats_plus_label[:,:-1] # features only\\nfeats_plus_label_scaled = np.column_stack((feats_plus_label, labels))\\ntrain = feats_plus_label_scaled[nids < 550]\\ntest = feats_plus_label_scaled[nids >= 550]\\ntrain = print(feats_df[feats_df.])'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "nids = meta_np['nid']\n",
    "feats_df['nids'] = nids\n",
    "print(feats_df.columns)\n",
    "'''labels = feats_plus_label[:,-1] # labels only\n",
    "feats_plus_label = feats_plus_label[:,:-1] # features only\n",
    "feats_plus_label_scaled = np.column_stack((feats_plus_label, labels))\n",
    "train = feats_plus_label_scaled[nids < 550]\n",
    "test = feats_plus_label_scaled[nids >= 550]\n",
    "train = print(feats_df[feats_df.])'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Finding Mislabeled Examples\n",
    "\n",
    "This task ties together the work you did for the unsupervised and supervised exercises.  Here's how to get started.\n",
    "\n",
    "1. Cluster the entire labeled set provided to you.  How you choose to do the clustering is up to you.  I would recommend getting your clustering results into a two dimensional space that you can plot, but this is not strictly necessary.\n",
    "\n",
    "2. Apply the labels to the clusters you've created and plot them.  If you're working in a >=3-dimensional space, find a way to print the candids in each cluster.  You can sort the list by examples that are closet to the centroids, and print their associated labels.\n",
    "\n",
    "3. Look at some postage stamps of examples you suspect are mislabeled.  Can you devise a simple way to identify a set of mislabeled examples?  Can you come up with an estimate of how many examples are mislabeled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
